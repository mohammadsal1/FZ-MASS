Project Report: Developing an Autonomous Driving System using ROS 2 and Computer Vision
​Our project aims to build an autonomous driving system based on the ROS 2 environment, Computer Vision libraries (OpenCV), and AI models (YOLO). Our work focused on developing a "brain" for the car, capable of real-time image processing to make driving decisions. We programmed a control system utilizing a State Machine to manage the car's behavior when approaching traffic signs (such as Stop and Yield) and traffic lights. The system gradually reduces speed, stops for the required duration, and safely resumes motion. Additionally, we integrated LiDAR sensor readings with auxiliary cameras to form a collision avoidance system.
​During the development phase, we conducted several experiments to optimize the system's performance, facing engineering challenges that required decisive action. Initially, we worked on integrating a GPS sensor to handle navigation and global path planning. However, after several tests, we encountered noticeable issues with GPS coordinate accuracy and signal drift within the simulation environment, which negatively impacted the car's stability. Consequently, we made an engineering decision to exclude the GPS and rely entirely on Computer Vision and local sensors (LiDAR) as a more robust and reliable alternative for real-time guidance and decision-making.
​The final challenge we faced, which represents the current limitation of our system, is "Strict Lane Keeping." The current system successfully detects the color of the asphalt (the black road) and avoids driving onto the white sidewalks, making the car fully capable of staying within the general boundaries of the road. However, the limitation lies in our center-tracking algorithm, which evaluates the entire road area rather than focusing exclusively on specific lane markings. As a result, the car tends to drive in the middle of the wide road or drift between lanes instead of maintaining its specific assigned lane. We made numerous attempts to tune the PID controller parameters and adjust the image processing algorithms to correct this deviation. While the car remains safely on the road, strict lane keeping remains our final software challenge. Resolving this in the future will require building a dedicated algorithm to track the yellow and white lane lines rather than tracking the drivable road area as a whole.
